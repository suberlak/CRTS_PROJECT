{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix B : wiggles explained "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we insert all code needed to make Appendix  B figure.  Other experiments are kept in D_Fig_2_CRTS_sel_r_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'CRTS_paper_modules' from '/Users/chris/GradResearch/CRTS_PROJECT/code/CRTS_paper_modules.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from astroML.stats import median_sigmaG\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import CRTS_paper_modules as mod\n",
    "import imp\n",
    "imp.reload(mod)\n",
    "#reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping CRTS-SDSS quasars catalog from ../data_products/CRTS_SDSS_catalogs/CRTS_SDSS_cross_matched_qso_DB_QSO_catalog.txt\n",
      "Read in 7601 quasars from CRTS\n",
      "zipping CRTS-SDSS stars catalog...\n",
      "Read in catalog for 48250 stars from CRTS \n"
     ]
    }
   ],
   "source": [
    "cols1, qso_cat = mod.get_qso_catalog() \n",
    "cols2 , star_cat= mod.get_stars_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The motivation for the additional panel is that it seems to me that the oscillation\n",
    "problem might not have anything to do with the actual sample size. It could be that\n",
    "systematic photometric calibration errors are large when comparing data obtained\n",
    "six months apart than for data obtained at the same time of year. To test this\n",
    "hypothesis, I propose to redo the middle panel (sigmaG with raw measurements)\n",
    "as the 6th panel where, instead of using all the data points when computing sigmaG,\n",
    "you *randomly subselect* 20,000 points. This number comes from the bottom panel \n",
    "where I see that counts vary from about 200,000 to about 0. Choosing a random\n",
    "sample of 20,000 points will allow you to get good results to beyond t2-t1 ~ 1500\n",
    "and thus you should see (or not) the first four wiggles in sigmaG. I think that the\n",
    "amplitude of sigmaG for the first four wiggles will remain about the same when you \n",
    "always use 20,000 random points (when you have fewer than 20,000 points, donâ€™t\n",
    "plot any points). This will demonstrate that the wiggles are not due to varying \n",
    "sample size. If the amplitude becomes much smaller instead, then I am wrong\n",
    "about calibration problems and the oscillations are indeed caused (somehow)\n",
    "by the varying sample size.\"  (Zeljko's email   5/4/17 )  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using now only lightcurves with SDSS  17.000000< r < 18.000000\n",
      "\n",
      "Choosing stars with  SDSS   -1.00<g-i<3.00\n",
      " These cuts reduced the number of stars  in the sample from 48250 to 5790\n",
      "\n",
      "Reading in tau,xi,ei  for 5790 objects\n",
      "\n",
      "Using structure function master files from ../data_products/sf_file_per_LC/stars/\n",
      "[##########] 100.00%\n",
      "Finished reading all master files for the selected objects ...\n",
      "\n",
      "Using now only lightcurves with SDSS  18.000000< r < 18.500000\n",
      "\n",
      "Choosing stars with  SDSS   -1.00<g-i<3.00\n",
      " These cuts reduced the number of stars  in the sample from 48250 to 3487\n",
      "\n",
      "Reading in tau,xi,ei  for 3487 objects\n",
      "\n",
      "Using structure function master files from ../data_products/sf_file_per_LC/stars/\n",
      "[######### ] 99.94%\n",
      "Finished reading all master files for the selected objects ...\n",
      "\n",
      "Using now only lightcurves with SDSS  18.500000< r < 19.000000\n",
      "\n",
      "Choosing stars with  SDSS   -1.00<g-i<3.00\n",
      " These cuts reduced the number of stars  in the sample from 48250 to 3825\n",
      "\n",
      "Reading in tau,xi,ei  for 3825 objects\n",
      "\n",
      "Using structure function master files from ../data_products/sf_file_per_LC/stars/\n",
      "[##########] 100.00%\n",
      "Finished reading all master files for the selected objects ...\n"
     ]
    }
   ],
   "source": [
    "# Code to select a sample of xi , ei points, treating all \n",
    "# stars together ... \n",
    "# this is what makes  detail_dic{}\n",
    "\n",
    "imp.reload(mod)\n",
    "\n",
    "Min_arr = [17, 18,   18.5 ]\n",
    "Max_arr = [18, 18.5, 19   ]\n",
    "\n",
    "detail_dic = {}\n",
    "#detail_dic['qso'] = {}\n",
    "detail_dic['stars'] = {}\n",
    "\n",
    "mag = 'r'   # which magnitudes to use for cutting and reporting \n",
    "inDirStars   = '../data_products/sf_file_per_LC/stars/'\n",
    "inDirQSO = '../data_products/sf_file_per_LC/qso_detailed/'\n",
    "        \n",
    "\n",
    "for i in range(len(Min_arr)):\n",
    "    Min = Min_arr[i]\n",
    "    Max = Max_arr[i]\n",
    "\n",
    "    print('\\nUsing now only lightcurves with SDSS  %f< %s < %f' % (Min, mag, Max))\n",
    "     \n",
    "    # no need for QSO to prove our point... \n",
    "    #detail_dic['qso'][Min] = mod.faster_read_xi_ei(inDirSF = inDirQSO, \n",
    "    #                                               good_ids= mod.cut_qso(qso_cat=qso_cat, mMin = Min, \n",
    "    #                                               mMax=Max, mErrMax = 0.3, cut_mag=mag), detailed=True)\n",
    "\n",
    "    # we combine blue and red stars by choosing g-i from   -1 to 1 and 1 to 3 together \n",
    "    detail_dic['stars'][Min] = mod.faster_read_xi_ei(inDirSF =inDirStars,  \n",
    "                               good_ids = mod.cut_stars(star_cat = star_cat, mMin = Min, \n",
    "                               mMax=Max, mErrMax = 0.3, gi_Min = -1, gi_Max=3, \n",
    "                               cut_mag=mag + '_mMed'), \n",
    "                               detailed=None)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we will save our Fig_B1 files in /Users/chris/GradResearch/CRTS_PROJECT/data_products/Fig_B1_data/2017-06-06/\n"
     ]
    }
   ],
   "source": [
    "# Make a new dir ... \n",
    "# Set a directory to save the results...\n",
    "outDir = os.path.join(os.getcwd()[:-4],'data_products/'+'Fig_B1_data', \n",
    "                      datetime.datetime.now().strftime('%Y-%m-%d')+ '/')\n",
    "if not os.path.exists(outDir): os.system('mkdir %s' % outDir)\n",
    "                      \n",
    "print('Today we will save our Fig_B1 files in %s'%outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stars': {17: {'ei': array([ 0.06876772,  0.05332401,  0.07006204, ...,  0.06363961,\n",
       "           0.05408327,  0.05408327]),\n",
       "   'tau': array([  9.02300000e-01,   9.46600000e-01,   9.62500000e-01, ...,\n",
       "            2.99781650e+03,   2.99993830e+03,   3.00292330e+03]),\n",
       "   'xi': array([-0.0192,  0.0002, -0.0234, ..., -0.0425,  0.125 ,  0.135 ])},\n",
       "  18: {'ei': array([ 0.09715189,  0.0958203 ,  0.10572138, ...,  0.05315073,\n",
       "           0.05315073,  0.05315073]),\n",
       "   'tau': array([  8.94600000e-01,   9.95100000e-01,   1.02460000e+00, ...,\n",
       "            2.89205550e+03,   2.89317740e+03,   2.91601500e+03]),\n",
       "   'xi': array([-0.1252, -0.3132, -0.2025, ..., -0.0225, -0.0925, -0.135 ])},\n",
       "  18.5: {'ei': array([ 0.11161205,  0.08565892,  0.12429855, ...,  0.11120899,\n",
       "           0.08849542,  0.08849542]),\n",
       "   'tau': array([  9.02300000e-01,   9.46600000e-01,   9.65900000e-01, ...,\n",
       "            2.99781650e+03,   2.99987370e+03,   3.00283650e+03]),\n",
       "   'xi': array([ 0.14  , -0.144 , -0.512 , ..., -0.0825,  0.0515,  0.044 ])}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detail_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the  detailed_dic dictionary into files organised by object - Min - Max \n",
    "for obj in detail_dic.keys(): \n",
    "    for i in range(len(Min_arr)) : \n",
    "        Min = Min_arr[i]\n",
    "        Max = Max_arr[i]\n",
    "        np.save(outDir + obj+'_' +str(Min)+'-'+str(Max) , detail_dic[obj][Min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################################################\n",
    "# Read detail_dic  using the code above : reproduced here for clarity \n",
    "########################################################################\n",
    "\n",
    "outDir = '../data_products/Fig_2_data/2017-04-19/'\n",
    "\n",
    "# Load the files if needed later ....\n",
    "detail_dic = {}\n",
    "for obj in ['qso', 'stars'] : \n",
    "    detail_dic[obj] = {}\n",
    "    \n",
    "    for i in range(len(Min_arr)) : \n",
    "        Min = Min_arr[i]\n",
    "        Max = Max_arr[i]\n",
    "        detail_dic[obj][Min] = np.load(outDir + obj+'_' +str(Min)+'-'+str(Max)+'.npy').item()\n",
    "        \n",
    "print('Read detailed xi, ei data from %s'%outDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "from matplotlib import rcParams\n",
    "#matplotlib.rcParams['font.size'] = 17\n",
    "#matplotlib.rc('xtick', labelsize=15) \n",
    "#matplotlib.rc('ytick', labelsize=15) \n",
    "rcParams['ytick.labelsize'] = 25\n",
    "rcParams['xtick.labelsize'] = 25\n",
    "rcParams['axes.labelsize'] = 35\n",
    "rcParams['axes.linewidth'] = 3\n",
    "rcParams['font.size'] = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do random selection and calculating mean tau ... \n",
    "# So that plotting can be done separately with just \n",
    "# a small fraction of data ... \n",
    "\n",
    "#bin_size_days = 20\n",
    "obj = 'stars'\n",
    "\n",
    "plot_dic = {}\n",
    "\n",
    "for Min , Max in zip([17,18,18.5], [18,18.5,19]):\n",
    "    plot_dic[Min] = {}\n",
    "    \n",
    "    # read in the points \n",
    "    tau = detail_dic[obj][Min]['tau']\n",
    "    xi  = detail_dic[obj][Min]['xi']\n",
    "\n",
    "    # randomly  select points...\n",
    "    # sigmaG (raw measurements ) : randomly subselect 20000 points \n",
    "    # https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html \n",
    "    indices = np.arange(len(xi))\n",
    "    size = 20000 \n",
    "\n",
    "    # first split xi, tau into 200 bins  \n",
    "    stats_temp = binned_statistic(tau, xi, statistic='count', bins=200)\n",
    "\n",
    "    # go over each bin, and calculate the sigmaG(xi) using random resample of N points.\n",
    "    sigmaG_xi = np.zeros_like(stats_temp.statistic)\n",
    "    N_pts  = 20000\n",
    "\n",
    "    sigmaG = lambda x : 0.7413 *(np.percentile(x,75) - np.percentile(x,25))\n",
    "\n",
    "    for N in np.sort(np.unique(stats_temp.binnumber)): \n",
    "        xi_per_bin = xi[stats_temp.binnumber == N] # choose points in the N-th bin\n",
    "        # randomly select 'N_pts'  from each bin. \n",
    "        # If there is less than N_pts in the bin,  then return NaN\n",
    "        if len(xi_per_bin) >= N_pts : \n",
    "            # randomly select N_pts points, and make sure that each point \n",
    "            # is drawn only once ! \n",
    "            xi_sample = np.random.choice(xi_per_bin, size = N_pts, replace = False)\n",
    "            sigmaG_xi[N-1] = sigmaG(xi_sample)\n",
    "        else :  # if the number of points per bin is less than N_pts, then set \n",
    "            # the sigmaG to nan, or 0, or some other number. \n",
    "            sigmaG_xi[N-1] = np.nan \n",
    "\n",
    "    mean_tau = (stats_temp.bin_edges[:-1] + stats_temp.bin_edges[1:])/2\n",
    "    bin_sigmaG = sigmaG_xi\n",
    "\n",
    "    plot_dic[Min]['mean_tau'] = mean_tau\n",
    "    plot_dic[Min]['bin_sigmaG'] = bin_sigmaG\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot using results of selecting equal number of points per bin ...\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax3 = plt.subplots(1,1, figsize=(12,6), sharex=True)\n",
    "\n",
    "# set all plot parameters\n",
    "lh_w   = 1.0  # horizontal line thickness \n",
    "lh_st  = '--' # horizontal line style \n",
    "lh_al  = 0.5  # horizontal line alpha parameter \n",
    "\n",
    "pre = {'qso':'QSO', 'stars':'Stars'}\n",
    "cm = plt.cm.get_cmap('RdYlBu')\n",
    "\n",
    "for Min in [17,18,18.5] : \n",
    "    print('N bins with lt 20000 points : %d'% np.sum(np.isnan(plot_dic[Min]['bin_sigmaG'])))\n",
    "    ax3.scatter(plot_dic[Min]['mean_tau'],  plot_dic[Min]['bin_sigmaG'], \n",
    "                label = str(Min)+'-'+str(Min+0.5), alpha=0.7)\n",
    "#ax3.set_title(pre[obj] + ' '+str(Min)+'-'+str(Max)+\\\n",
    "#              ', bin count =  '+str(N_pts) , fontsize=20 )\n",
    "# plt.legend(loc='best')  \n",
    "\n",
    "#if Min == 18 : \n",
    "#    ymin = 0.04\n",
    "#elif Min == 18.5 :\n",
    "#    ymin = 0.07    \n",
    "dy = 0.13\n",
    "ax3.set_ylim(0.02, ymin+dy)\n",
    "#ax3.set_ylim(0.06, 0.17)\n",
    "ax3.set_xlim(-400, 3300)\n",
    "yticks = ax3.get_yticks()\n",
    "ax3.set_yticks(yticks[1:-1]) \n",
    "ax3.set_ylabel(r'$\\sigma_{G}(\\Delta m)\\,\\,  [mag]$')\n",
    "ax3.set_xlabel(r'$\\Delta t \\, \\, [days]$')\n",
    "plt.legend(loc='upper right', fontsize=20)\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "fig.subplots_adjust(hspace=0)\n",
    "\n",
    "for ax in [ax3] : \n",
    "    ax.grid(axis='x')\n",
    "    for y in [0.05,0.1, 0.15]:\n",
    "        ax.axhline(y=y, color='black', lw=lh_w, ls=lh_st,alpha=lh_al)\n",
    "\n",
    "title = pre[obj] +'_CRTS_wiggles.png'\n",
    "plt.savefig(outDir+title,  bbox_inches='tight')\n",
    "print('Saved as %s'%outDir+title)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

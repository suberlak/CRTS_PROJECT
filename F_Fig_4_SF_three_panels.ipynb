{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from astroML.stats import median_sigmaG\n",
    "from scipy.stats import binned_statistic\n",
    "import CRTS_paper_modules as mod\n",
    "import datetime\n",
    "from matplotlib import rcParams\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make Fig. 4 I would read files in a given mag range,  and then loop over objects in 11)a) , setting appropriate fc ( as in file   SigmaG_chi_-StarsB.txt  in  data_products/Fig_3_data/2016-06-07/   ) \n",
    "\n",
    "Instead of using a single fc for the entire range, I apply the fitted correction coefficient  power law:\n",
    "\n",
    "\n",
    "$\\sigma_{G}(\\chi_{Blue}) = f_{c} = a \\, \\log_{10}(\\Delta_{t}) + b$ , \n",
    "\n",
    "where $a$ and $b$ are set for each magnitude from the linear fit  (I read them in from data_products/Fig_3_data/2016-06-07/fc_starsB_a_b_coeff.txt  ) \n",
    "\n",
    "    mag     | a       | b \n",
    "    17-18   | 0.02418 | 0.08325  \n",
    "    18-18.5 | 0.02650 | 1.04461\n",
    "    18.5-19 | 0.02477 | 1.22914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we will save our Fig_4 files in /local/tmp/suberlak/CRTS_PROJECT/data_products/Fig_4_data/2016-06-13/\n"
     ]
    }
   ],
   "source": [
    "# Read in the linear correction coefficients....\n",
    "File = '/local/tmp/suberlak/CRTS_PROJECT/data_products/Fig_3_data/2016-06-07/fc_starsB_a_b_coeff.txt'\n",
    "colnames = open(File,'r').read().splitlines()[0][1:].split()\n",
    "datatable = np.genfromtxt(File, dtype=float)\n",
    "coeffs = {}\n",
    "for label, column in zip(colnames, datatable.T):\n",
    "    coeffs[label] = column\n",
    "    \n",
    "# Set a directory to save the results...\n",
    "outDir = os.path.join(os.getcwd()[:-4]+'data_products/'+'Fig_4_data/')\n",
    "if not os.path.exists(outDir): os.system('mkdir %s' % outDir)\n",
    "                      \n",
    "outDir = os.path.join(os.getcwd()[:-4],'data_products/'+'Fig_4_data', \n",
    "                      datetime.datetime.now().strftime('%Y-%m-%d')+ '/')\n",
    "if not os.path.exists(outDir): os.system('mkdir %s' % outDir)\n",
    "\n",
    "print('Today we will save our Fig_4 files in %s'%outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in xi, ei  for the objects in a given mag range ... Not the same as Fig_3, because there we only have samples of log_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping CRTS-SDSS quasars catalog from  ../data_products/CRTS_SDSS_cross_matched_qso_DB_QSO_catalog.txt  ...\n",
      "Read in  7601 , quasars from CRTS\n",
      "zipping CRTS-SDSS stars catalog...\n",
      "Read in catalog for  48250 , stars from CRTS\n"
     ]
    }
   ],
   "source": [
    "cols1, qso_cat = mod.get_qso_catalog() \n",
    "cols2 , star_cat= mod.get_stars_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to loop that, and the calculation of xi, ei  below,  over the three magnitude ranges... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using now only lightcurves with SDSS  18.500000< r < 19.000000\n",
      "\n",
      " These cuts reduced the number of stars  in the sample from 48250  to  1496\n",
      "Returning only QSO which had an SDSS counterpart within 0.000278 radians\n",
      "\n",
      " These cuts reduced the number of qso  in the sample from 7601  to  747\n",
      "Reading in xi, ei for bin  r_cut\n",
      "making new delflx, tau, xi arrays\n",
      "\n",
      "\n",
      "----- Already read 99% of qso \n",
      "\n",
      "----- Already read 99% of Blue Stars \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the magnitude range \n",
    "Min  = 18.5\n",
    "Max  = 19\n",
    "\n",
    "objects_in_cut = {}\n",
    "\n",
    "mag = 'r'\n",
    "cut_mag = mag\n",
    "\n",
    "print('\\nUsing now only lightcurves with SDSS  %f< %s < %f' % (Min, cut_mag, Max))\n",
    "\n",
    "# use only qso and blue stars since these are the ones that we are plotting ...\n",
    "good_ids_S_blue = mod.cut_stars(star_cat = star_cat, mMin = Min, mMax=Max, mErrMax = 0.3, gi_Min = -1,\n",
    "                                          gi_Max=1, cut_mag=cut_mag + '_mMed')\n",
    "\n",
    "good_ids_QSO = mod.cut_qso(qso_cat=qso_cat, mMin = Min, mMax=Max, mErrMax = 0.3, \n",
    "                                           cut_mag=cut_mag)\n",
    "objects_in_cut[mag] = {'starsB':good_ids_S_blue, 'qso':good_ids_QSO}\n",
    "\n",
    "\n",
    "## Since I'm only using r_cut,   I won't compare it with g_cut .  Thus making r_bin is the same as r_cut  \n",
    "\n",
    "bins = {}\n",
    "bin_types = ['r_cut']\n",
    "\n",
    "objects = objects_in_cut['r'].keys()\n",
    "\n",
    "# first need to explicitly initialize the dictionaries \n",
    "for b in bin_types:\n",
    "    bins[b] = {}\n",
    "    \n",
    "for obj in objects : \n",
    "    bins['r_cut'][obj] =  objects_in_cut['r'][obj]\n",
    "    \n",
    "## Read in the xi, ei for objects in that mag range ... \n",
    "inDirStars   = '../data_products/sf_file_per_LC/stars/'\n",
    "inDirQSO = '../data_products/sf_file_per_LC/qso/'\n",
    "\n",
    "out_dic = {}\n",
    "\n",
    "#for b in bins.keys():\n",
    "# read in only r_cut \n",
    "\n",
    "b = 'r_cut'\n",
    "print 'Reading in xi, ei for bin ', b\n",
    "out_dic[b] = {}   # initialize the dic \n",
    "\n",
    "good_ids_S_blue = bins[b]['starsB']\n",
    "good_ids_QSO = bins[b]['qso']\n",
    "\n",
    "qso, starB, =  mod.read_xi_ei(inDirStars, good_ids_S_blue, inDirQSO, good_ids_QSO)\n",
    "\n",
    "# put into a dictionary : makes it more explicit \n",
    "out_dic[b] = {'starsB': starB, 'qso':qso}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate sigma approx and sigma full, applying correction factor to errors in each bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for all imports of my functions, \n",
    "# make python aware of my packages...\n",
    "import sys\n",
    "sys.path.insert(0, '/astro/users/suberlak/S13Agg_analysis/packages/')\n",
    "import variabilityFunctions as varF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we will save our Fig_4 files in /local/tmp/suberlak/CRTS_PROJECT/data_products/Fig_4_data/2016-06-08/\n",
      "\n",
      " For obj =  qso\n",
      " --- Calculating mu, sigma for bin 200 Results saved as  /local/tmp/suberlak/CRTS_PROJECT/data_products/Fig_4_data/2016-06-08/r_cut_18.5-19_qso.txt\n",
      "\n",
      " For obj =  starsB\n",
      " --- Calculating mu, sigma for bin 200 Results saved as  /local/tmp/suberlak/CRTS_PROJECT/data_products/Fig_4_data/2016-06-08/r_cut_18.5-19_starsB.txt\n",
      "Done with calculating panel data \n"
     ]
    }
   ],
   "source": [
    "# set the bin number \n",
    "nbins = 200 \n",
    "\n",
    "          \n",
    "print('Today we will save our Fig_4 files in %s'%outDir)\n",
    "\n",
    "# Loop over objects in the dictionary  \n",
    "for obj in ['qso','starsB'] : # out_dic[b].keys()\n",
    "    print '\\n For obj = ', obj\n",
    "    # obj = 'qso'  # or starsB,  starsR \n",
    "    m_ij = out_dic['r_cut'][obj][0]\n",
    "    tau =  out_dic['r_cut'][obj][1]\n",
    "    e_ij = out_dic['r_cut'][obj][2]\n",
    "\n",
    "\n",
    "    # Pull out some tau to plot means : common to all panels \n",
    "    binned_tau = binned_statistic(tau, tau, statistic='mean', bins=nbins)\n",
    "    mean_tau = binned_tau[0]\n",
    "    \n",
    "    # Make an array of correction coefficients per bin, using the coefficients from the file ...  \n",
    "    a = coeffs['a'][coeffs['rMagMin'] == Min]\n",
    "    b = coeffs['b'][coeffs['rMagMin'] == Min]\n",
    "    binned_fc =  a* np.log10(binned_tau[0]) + b\n",
    "    \n",
    "    # Take N from each bin... 'count' function works like a regular histogram\n",
    "    binned_count = binned_statistic(tau, tau, statistic='count', bins=nbins)\n",
    "    bin_count = binned_count[0]\n",
    "    \n",
    "    # checking for empty bins : either mean or some custom function, but not\n",
    "    # count! If statistic='count', then check for 0's , and not for nan's/ \n",
    "    non_empty_bins = np.bitwise_not(np.isnan(mean_tau))\n",
    "\n",
    "    # reassign number of points in a bin and  tau position \n",
    "    bin_count = bin_count[non_empty_bins]\n",
    "    mean_tau = mean_tau[non_empty_bins]\n",
    "\n",
    "\n",
    "    # Which point belongs to which bin\n",
    "    bin_number  = binned_tau[2]\n",
    "\n",
    "    ####  Panel 1 : Standard Deviation \n",
    "    rms_std = lambda x : np.std(x)\n",
    "    stdev_binned = binned_statistic(tau, m_ij, statistic = rms_std, \n",
    "                                              bins=nbins)\n",
    "    bin_stdev = stdev_binned[0][non_empty_bins]  \n",
    "\n",
    "\n",
    "    ##### Panel 2  : Gaussian rms  \n",
    "    rms_robust = lambda x : 0.7414 *(np.percentile(x,75) - np.percentile(x,25))\n",
    "    bin_sigma_G = binned_statistic(tau, m_ij, statistic = rms_robust, \n",
    "                                      bins=nbins)[0][non_empty_bins]\n",
    "\n",
    "    # Loop over all bins  calculating approximate mu and sigma \n",
    "    mu_bins = {}\n",
    "    sig_bins = {}\n",
    "\n",
    "    sig_bins['approx'] = np.zeros(nbins)\n",
    "    mu_bins['approx'] = np.zeros(nbins)\n",
    "    sig_bins['full'] = np.zeros(nbins)\n",
    "    mu_bins['full'] = np.zeros(nbins)\n",
    "    \n",
    "    for N in np.unique(bin_number):\n",
    "        print('\\r --- Calculating mu, sigma for bin %d' % N),\n",
    "        xi = m_ij[bin_number == N]\n",
    "        fc_bin = binned_fc[N-1]\n",
    "        ei = fc_bin * e_ij[bin_number == N]\n",
    "    \n",
    "        mu_approx, sig_approx = varF.approximate_mu_sigma(xi, ei)\n",
    "        mu_full, sig_full =  varF.get_mu_sigma(xi,ei)\n",
    "        \n",
    "        sig_bins['approx'][N-1] = sig_approx\n",
    "        sig_bins['full'][N-1] = sig_full\n",
    "        \n",
    "        mu_bins['approx'][N-1] = mu_approx\n",
    "        mu_bins['full'][N-1] = mu_full \n",
    "\n",
    "    # Save the results of calculation  : Panel 1,2,3,4 \n",
    "    fname = outDir+ 'r_cut'+'_'+str(Min)+'-'+str(Max)+'_'+obj+'.txt'\n",
    "    \n",
    "\n",
    "    data = np.column_stack((mean_tau, bin_stdev, bin_sigma_G, sig_bins['full'], \n",
    "                            sig_bins['approx'], mu_bins['full'], mu_bins['approx'], bin_count, binned_fc))\n",
    "\n",
    "    header = 'meanTau   stdev    sigmaG   sigmaFull  sigmaApprox   muFull  muApprox   binCount  binFcorr'\n",
    "    np.savetxt(fname, data, fmt = '%s', delimiter = ' ' , header=header )\n",
    "    print 'Results saved as ', fname\n",
    "\n",
    "print 'Done with calculating panel data '    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in plotting data from  saveFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have  already calculated statistics for each bin,  can simply read the file, and proceed to plotting, skipping steps above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libopenblasp-r0-39a31c03.2.18.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-bcbe1bd41fb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#from scipy.optimize import curve_fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# the directory with results previously calculated ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpackages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_newdocs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m     __all__ = ['add_newdocs',\n\u001b[0;32m    182\u001b[0m                \u001b[1;34m'ModuleDeprecationWarning'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/numpy/add_newdocs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0madd_newdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m###############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/numpy/lib/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtype_check\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindex_tricks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfunction_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/numpy/lib/type_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m            'common_type']\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumeric\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mobj2sctype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/astro/apps6/anaconda2.0/lib/python2.7/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menvkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0menv_added\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menvkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0menvkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: libopenblasp-r0-39a31c03.2.18.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from scipy.optimize import curve_fit\n",
    "from collections import OrderedDict\n",
    "\n",
    "# the directory with results previously calculated ... \n",
    "outDir = '/local/tmp/suberlak/CRTS_PROJECT/data_products/Fig_4_data/2016-06-08/'\n",
    "\n",
    "plot_data = OrderedDict()\n",
    "\n",
    "Min_arr = [17,18,18.5]\n",
    "Max_arr = [18, 18.5, 19]\n",
    "\n",
    "for mag in Min_arr:\n",
    "    plot_data[mag] = OrderedDict()\n",
    "    \n",
    "for i in range(len(Min_arr)):\n",
    "    Min = Min_arr[i]\n",
    "    Max = Max_arr[i]\n",
    "    for obj in ['qso','starsB']:\n",
    "        plot_data[Min][obj] = {}\n",
    "        \n",
    "        fname =  outDir+ 'r_cut'+'_'+str(Min)+'-'+str(Max)+'_'+obj+'.txt'\n",
    "        print 'Loading... ', fname \n",
    "        \n",
    "        colnames = open(fname,'r').read().splitlines()[0][1:].split()\n",
    "        d = np.genfromtxt(fname, dtype=float)\n",
    "        \n",
    "        for label, column in zip(colnames, d.T):\n",
    "            plot_data[Min][obj][label] = column\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rcParams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8ca33fcdd533>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ytick.labelsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xtick.labelsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'axes.labelsize'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m35\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rcParams' is not defined"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "def model_sf(t, sf_inf=0.25, tau = 1.0):\n",
    "    br = 1.0-np.exp(-t/tau)\n",
    "    sf = sf_inf * np.power(br,0.5)\n",
    "    return sf\n",
    "        \n",
    "        \n",
    "rcParams['ytick.labelsize'] = 25\n",
    "rcParams['xtick.labelsize'] = 25\n",
    "rcParams['axes.labelsize'] = 35\n",
    "rcParams['axes.linewidth'] = 3\n",
    "rcParams['font.size'] = 25\n",
    "rcParams.update({'figure.autolayout': False})\n",
    "\n",
    "\n",
    "obj_arr = ['qso',  'starsB']\n",
    "labels_arr = ['Quasars', 'Blue Stars']\n",
    "colors = ['black','blue']\n",
    "\n",
    "# set all plot parameters\n",
    "lh_w   = 1.0  # horizontal line thickness \n",
    "lh_st  = '--' # horizontal line style \n",
    "lh_al  = 0.5  # horizontal line alpha parameter \n",
    "\n",
    "# dot size \n",
    "p_size = 7\n",
    "p_al   = 0.5 \n",
    "\n",
    "# y limits for SF panels \n",
    "y_top  = 0.45\n",
    "y_bott = -0.05\n",
    "\n",
    "# y limits for mu approx \n",
    "y_mu_top = 0.1\n",
    "y_mu_bott = -0.1\n",
    "\n",
    "# x limits for ALL PANELS \n",
    "x_left = 0.5\n",
    "x_right = 3.7\n",
    "\n",
    "b = 'r_cut'\n",
    "\n",
    "fig,ax = plt.subplots(3,1, figsize=(12,12), sharex=True)\n",
    "fig.subplots_adjust(hspace=0)\n",
    "for i in range(len(Min_arr)):\n",
    "    Min = Min_arr[i]\n",
    "    Max = Max_arr[i]\n",
    "    for j in range(len(obj_arr)):\n",
    "        obj = obj_arr[j]\n",
    "        \n",
    "        plot = plot_data[Min][obj]\n",
    "        \n",
    "        #ax[i].scatter(np.log10(plot['meanTau']), plot['sigmaApprox'],  s=p_size, \n",
    "        #            alpha=p_al, label=labels_arr[j], \n",
    "        #              color=colors[j])\n",
    "        #err_sig = plot['sigmaApprox']* 1.06 / np.sqrt(plot['binCount'])\n",
    "        \n",
    "        #ax[i].errorbar(np.log10(plot['meanTau']), plot['sigmaApprox'],err_sig, linestyle='None',\n",
    "        #               color=colors[j],   alpha=p_al)#\n",
    "        \n",
    "        ax[i].scatter(np.log10(plot['meanTau']), plot['sigmaFull'], s=p_size, \n",
    "                    alpha=p_al, c ='cyan')\n",
    "        err_sig = plot['sigmaFull']* 1.06 / np.sqrt(plot['binCount'])\n",
    "        \n",
    "        ax[i].errorbar(np.log10(plot['meanTau']), plot['sigmaFull'],err_sig, linestyle='None',\n",
    "                       color=colors[j],   alpha=p_al)#\n",
    "        \n",
    "        if obj == 'qso' : \n",
    "            # Calculate the model DRW fit for QSO\n",
    "        \n",
    "            xdata = plot['meanTau']\n",
    "            sf = plot['sigmaFull']\n",
    "            popt, pcov = curve_fit(model_sf, xdata, sf)\n",
    "            y = model_sf(xdata, sf_inf=popt[0], tau = popt[1]) # tau 1 year in days \n",
    "\n",
    "            # Fold-in the error to the model SF , plot \n",
    "            # both folded and not-folded version \n",
    "            y_fold = np.sqrt((y ** 2.0)+ (err_sig ** 2.0) )\n",
    "            ax[i].plot(np.log10(xdata), y_fold , lw=3, c = 'green', ls='--')\n",
    "            ax[i].plot(np.log10(xdata), y , lw=3, c = 'orange', ls='--')\n",
    "\n",
    "            # text = r'$ \\mathrm{Model:}\\ \\tau=%.3f \\,\\mathrm{days} , \\ SF_{\\infty}=%.3f \\,\\mathrm{mag}$'%(popt[1],popt[0])\n",
    "            # ax[i].text(x=0.75, y=0.3,s = text )\n",
    "\n",
    "            \n",
    "for i in range(len(Min_arr)) :\n",
    "    \n",
    "    ax[i].text(1.0, 0.25, 'mag: '+str(Min_arr[i])+'-'+str(Max_arr[i]) )\n",
    "  \n",
    "    ax[i].set_ylabel(r'$SF$')\n",
    "    ax[i].set_ylim(bottom=y_bott, top=y_top)\n",
    "    ax[i].set_xlim(left=x_left, right=x_right)\n",
    "    ax[i].grid() \n",
    "    ax[i].hlines(y=0.1, xmin =0.5, xmax=1.7, color='green', lw = 4, linestyle = '--' , alpha = 0.8  )\n",
    "\n",
    "    ax[i].set_yticks([0,0.1,0.2,0.3,0.4])\n",
    "    ax[i].set_yticklabels(['0.0','0.1', '0.2', '0.3', '0.4'])\n",
    "    \n",
    "axbox = ax[0].get_position()\n",
    "x_value=0.3\n",
    "y_value=0.15\n",
    "legend = ax[0].lege\n",
    "nd(fancybox=True,loc=(axbox.x0 + x_value, axbox.y0 - y_value), fontsize=25)\n",
    "#rcParams['legend.numpoints'] = 1\n",
    "#legend.get_frame().set_edgecolor('1.0')\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "plt.rc('legend',**{'fontsize':16})\n",
    "#plt.setp(plt.gca().get_legend().get_texts(), fontsize='12')\n",
    "\n",
    "ax[-1].set_xlabel(r'$log_{10} (\\Delta {t})$ [days]') \n",
    "    \n",
    "#ax[-1].set_xlabel(r'$\\log_{10}{\\tau}$', fontsize=20)\n",
    "\n",
    "plt.savefig(outDir+'Fig_4_SF_QSO_starsB_r_cut.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17, 18, 18.5]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
